# -*- coding: utf-8 -*-
"""CURO DPGAN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1D_BPqvyWH5-Vz9N1-1Hi4E4vKngd_yda
"""

#ADDING DIFFERENTIAL PRIVACY TO DISCRIMINATOR
#https://medium.com/pytorch/differential-privacy-series-part-1-dp-sgd-algorithm-explained-12512c3959a3

pip install torchcsprng==0.1.3+cu101 -f https://download.pytorch.org/whl/torch_stable.html

pip install opacus

import os

import torch
from torch import nn
from torch import optim
import torchvision as tv
from torchvision.datasets import ImageFolder
from torch.utils.data import DataLoader
from opacus import privacy_analysis



class Generator(nn.Module):
    def __init__(self, latent_dim=100, batchnorm=True):
        """A generator for mapping a latent space to a sample space.
        The sample space for this generator is single-channel, 28x28 images
        with pixel intensity ranging from -1 to +1.
        Args:
            latent_dim (int): latent dimension ("noise vector")
            batchnorm (bool): Whether or not to use batch normalization
        """
        super(Generator, self).__init__()
        self.latent_dim = latent_dim
        self.batchnorm = batchnorm
        self._init_modules()

    def _init_modules(self):
        """Initialize the modules."""
        # Project the input
        self.linear1 = nn.Linear(self.latent_dim, 256*8*8, bias=False)
        self.bn1d1 = nn.BatchNorm1d(256*8*8) if self.batchnorm else None
        self.leaky_relu = nn.LeakyReLU()

        # Convolutions
        self.conv1 = nn.ConvTranspose2d(
                in_channels=256,
                out_channels=128,
                kernel_size=5,
                stride=1,
                padding=2,
                bias=False)
        self.bn2d1 = nn.BatchNorm2d(128) if self.batchnorm else None

        self.conv2 = nn.ConvTranspose2d(
                in_channels=128,
                out_channels=64,
                kernel_size=4,
                stride=2,
                padding=1,
                bias=False)
        self.bn2d2 = nn.BatchNorm2d(64) if self.batchnorm else None

        self.conv3 = nn.ConvTranspose2d(
                in_channels=64,
                out_channels=1,
                kernel_size=4,
                stride=2,
                padding=1,
                bias=False)
        self.tanh = nn.Tanh()

    def forward(self, input_tensor):
        """Forward pass; map latent vectors to samples."""
        #print ("in generator")
        #print ("input size" , input_tensor.shape)
        intermediate = self.linear1(input_tensor)
        intermediate = self.bn1d1(intermediate)
        intermediate = self.leaky_relu(intermediate)

        #print ("aftere linear layer size", intermediate.shape)
        intermediate = intermediate.view((-1, 256, 8, 8))
        #print ("after unflatten", intermediate.shape)
        intermediate = self.conv1(intermediate)
        #print ("after first conv layer size" , intermediate.shape)
        if self.batchnorm:
            intermediate = self.bn2d1(intermediate)
        intermediate = self.leaky_relu(intermediate)

        intermediate = self.conv2(intermediate)
        #print ("after second conv layer size" , intermediate.shape)
        if self.batchnorm:
            intermediate = self.bn2d2(intermediate)
        intermediate = self.leaky_relu(intermediate)

        intermediate = self.conv3(intermediate)
        output_tensor = self.tanh(intermediate)
        #print ("after third covn output shape", output_tensor.shape)
        #print()
        return output_tensor

import torch.nn as nn
import torch.nn.functional as F

class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()
        self.conv1 = nn.Conv2d(1, 64, 3)
        self.conv2 = nn.Conv2d(64, 32, 3)
        self.conv3 = nn.Conv2d(32, 16, 3)
        
        self.fc1 = nn.Linear(16 * 4 * 4, 1)
        """
        super(Discriminator, self).__init__()
        self.conv1 = nn.Conv2d(1, 8, 3)
        self.conv2 = nn.Conv2d(8, 16, 3)
        self.conv3 = nn.Conv2d(16, 30, 3)
        
        self.fc1 = nn.Linear(30 * 4 * 4, 84)
        self.fc2 = nn.Linear(84, 1)
        """
    def forward(self, x):
        #print ("tensor in discriminator size begninning")
        #print("in discriminator input", x.shape)
        x = F.max_pool2d(F.relu(self.conv1(x)), 2)
        #print ("After first convolution", x.shape)
        x = F.max_pool2d(F.relu(self.conv2(x)), 2)
        #print ("After second convolution", x.shape)
        x = F.relu(self.conv3(x))
        #print ("After third convolution", x.shape)
        x = x.view(-1, 16 * 4 * 4)
        x = torch.sigmoid(self.fc1(x))
        #print ("tensor in discriminator size end", x.size())
        #print ()
        return x

"""from opacus.utils import module_modification

model = module_modification.convert_batchnorm_modules(model)
inspector = DPModelInspector()
print(f"Is the model valid? {inspector.validate(model)}")

NEXT CELL CHANGES ADAM OPTIMIZER TO SGD
"""

from torch.nn.utils import clip_grad_norm_
from opacus import PrivacyEngine
class DCGAN():
    def __init__(self, latent_dim, noise_fn, dataloader,
                 batch_size=32, device='cpu', lr_d=1e-3, lr_g=2e-4):
        """A very basic DCGAN class for generating MNIST digits
        Args:
            generator: a Ganerator network
            discriminator: A Discriminator network
            noise_fn: function f(num: int) -> pytorch tensor, (latent vectors)
            dataloader: a pytorch dataloader for loading images
            batch_size: training batch size. Must match that of dataloader
            device: cpu or CUDA
            lr_d: learning rate for the discriminator
            lr_g: learning rate for the generator
        """
        self.generator = Generator(latent_dim).to(device)
        self.discriminator = Discriminator().to(device)
        self.noise_fn = noise_fn
        self.dataloader = dataloader
        self.batch_size = batch_size
        self.device = device
        self.criterion = nn.BCELoss()
        self.optim_d = optim.SGD(self.discriminator.parameters(), lr=lr_d)
        self.optim_g = optim.SGD(self.generator.parameters(), lr=lr_g)
        self.target_ones = torch.ones((batch_size, 1), device=device)
        self.target_zeros = torch.zeros((batch_size, 1), device=device)


        """attach privacy engine"""
        model = self.discriminator

        privacy_engine = PrivacyEngine(
            model,
            batch_size = 32,
            sample_size = len(dataloader),
            alphas = range(2,32),
            noise_multiplier = 1.3,
            max_grad_norm = 1.0,
        )

        privacy_engine.attach(self.optim_d)

        #privacy analysis
        #rdp = privacy_analysis.compute_rdp(sample_rate = 32, noise_multiplier = 1.3, steps = 0, alphas = range(2,32))
        #eps, opt_alpha = privacy_analysis.get_privacy_spent(range(2,32), rdp, delta=1e-5)

    def generate_samples(self, latent_vec=None, num=None):
        """Sample images from the generator.
        Images are returned as a 4D tensor of values between -1 and 1.
        Dimensions are (number, channels, height, width). Returns the tensor
        on cpu.
        Args:
            latent_vec: A pytorch latent vector or None
            num: The number of samples to generate if latent_vec is None
        If latent_vec and num are None then use self.batch_size
        random latent vectors.
        """
        num = self.batch_size if num is None else num
        latent_vec = self.noise_fn(num) if latent_vec is None else latent_vec
        with torch.no_grad():
            samples = self.generator(latent_vec)
        samples = samples.cpu()  # move images to cpu
        return samples

    def train_step_generator(self):
        """Train the generator one step and return the loss."""
        self.generator.zero_grad()

        latent_vec = self.noise_fn(self.batch_size)
        generated = self.generator(latent_vec)
        classifications = self.discriminator(generated)
        loss = self.criterion(classifications, self.target_ones)
        loss.backward()
        self.optim_g.step()
        return loss.item()

    def train_step_discriminator(self, real_samples):
        """Train the discriminator one step and return the losses."""
        self.discriminator.zero_grad()

        # real samples
        #print ("at train step discrim ")
        pred_real = self.discriminator(real_samples)
        #loss_real = self.criterion(pred_real, nn.functional.one_hot(self.target_ones))
        #print ("real size" , pred_real.size())
        #print ("target", self.target_ones)
        loss_real = self.criterion(pred_real, self.target_ones)

        # generated samples
        latent_vec = self.noise_fn(32)
        with torch.no_grad():
            fake_samples = self.generator(latent_vec)
        fake_samples = F.interpolate(fake_samples, size = (32,32))
        #print ("INTERPOLATED fake samples" , fake_samples.size())
        pred_fake = self.discriminator(fake_samples)
        #print ("fake size after discriminator" , pred_fake.size())
        #print ()
        loss_fake = self.criterion(pred_fake, self.target_zeros)

        # combine
        loss = (loss_real + loss_fake) / 2
        loss.backward()
        self.optim_d.step()
        return loss_real.item(), loss_fake.item()

    def train_epoch(self, print_frequency=10, max_steps=0):
        """Train both networks for one epoch and return the losses.
        Args:
            print_frequency (int): print stats every `print_frequency` steps.
            max_steps (int): End epoch after `max_steps` steps, or set to 0
                             to do the full epoch.
        """
        loss_g_running, loss_d_real_running, loss_d_fake_running = 0, 0, 0
        for batch, (real_samples, _) in enumerate(self.dataloader):
            real_samples = real_samples.to(self.device)
            ldr_, ldf_ = self.train_step_discriminator(real_samples)
            loss_d_real_running += ldr_
            loss_d_fake_running += ldf_
            loss_g_running += self.train_step_generator()
            if print_frequency and (batch+1) % print_frequency == 0:
                print(f"{batch+1}/{len(self.dataloader)}:"
                      f" G={loss_g_running / (batch+1):.3f},"
                      f" Dr={loss_d_real_running / (batch+1):.3f},"
                      f" Df={loss_d_fake_running / (batch+1):.3f}",
                      end='\r',
                      flush=True)
            if max_steps and batch == max_steps:
                break
        if print_frequency:
            print()
        loss_g_running /= batch
        loss_d_real_running /= batch
        loss_d_fake_running /= batch

        print (f" G={loss_g_running:.3f},"
                f" Dr={loss_d_real_running:.3f},"
                f" Df={loss_d_fake_running :.3f}")

        return (loss_g_running, (loss_d_real_running, loss_d_fake_running))

"""# 
$$ \min_G \max_D(D,G) = E[\log(D(X)] + E(\log(1 - D(G(z)))] $$
"""

def main():
    import matplotlib.pyplot as plt
    from time import time
    batch_size = 32
    epochs = 100
    latent_dim = 100
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


    transform = tv.transforms.Compose([
            tv.transforms.Grayscale(num_output_channels=1),
            tv.transforms.Resize((32,32)),
            tv.transforms.ToTensor(),
            tv.transforms.Normalize((0.5,), (0.5,))
            ])
    dataset = tv.datasets.MNIST(root='./MNISTdata', train=True,
                                        download=True, transform=transform)
    dataloader = torch.utils.data.DataLoader(dataset, batch_size=32,
                                          shuffle=True, num_workers=2)

    noise_fn = lambda x: torch.randn((x, latent_dim), device=device)
    gan = DCGAN(latent_dim, noise_fn, dataloader, device=device, batch_size=batch_size)
    start = time()
    for i in range(30):
        print(f"Epoch {i+1}; Elapsed time = {int(time() - start)}s")
        gan.train_epoch()
        images = gan.generate_samples() * -1  # invert colours, for aesthetics
        ims = tv.utils.make_grid(images, normalize=True)
        plt.imshow(ims.numpy().transpose((1,2,0)))
        plt.show()


if __name__ == "__main__":
    main()

